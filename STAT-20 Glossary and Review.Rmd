---
title: "A continuing overview of STAT 20 R"
author: "JE Hug"
date: "9/16/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Welcome to this document created by Josh Hug, one of the GSI's for STAT 20. This document will try and keep up with our R progress as we go on and I will add in depth (time permitting) explanations of what we are doing as I go on. Remember to check [github](https://github.com/guhauhsoj/STAT20-Hug) for the latest updates to this document as it progresses!


A generic glossary of R commands that we have used so far.


```{r, message=FALSE}
# these are the packages we are using so far

library(dplyr)
library(ggplot2)
```

I'll begin with some simple use of the main dplyr functions we use, on the palmer penguins data set (make sure to install it if you don't have it yet). I prefer using this dataset over something like iris due to the fact that while iris is a classic dataset, it was compiled by Ronald Fisher (a fervent eugenicist) and published in a eugenics journal originally. This dataset provides a nice alternative with similar properites. 


# 1 Filter, Select, Mutate Basics

The key facts here are to use select if we want 

```{r}

# Here I will use the palmer penguins data set

# if you don't have it installed

# install.packages("palmerpenguins") 

library(palmerpenguins) # where this data set comes from


glimpse(penguins) # a nice function to take an easy look at the data

```

Suppose I wanted to make a new column bill_length_cm and body_mass_kg (where I convert units into cm and kg respectively)

We can use mutate to add a new column as some function of another column


```{r}


new_pen <- mutate(penguins, bill_length_cm = bill_length_mm / 10, body_mass_kg = body_mass_g / 1000 )

glimpse(new_pen)


```

Now suppose I want penguins that weigh less than like 3000 g (3kg) only. Since this is subsetting over rows with a specific condition we use the filter function from dplyr.



```{r}

new_pen_light<- filter(new_pen, body_mass_kg <3 )

glimpse(new_pen_light)

```





# 2 Histograms in R

Take a look at this [cheat sheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf), you're probably extremely overwhelmed by this and personally I don't know what at least half of the stuff on this page does but it will save you a lot of time from googling. There are actually [cheat sheets](https://rstudio.com/resources/cheatsheets/) for most tidyverse (what these packages are a part of) packages so you can check out ones for dplyr and such.



## 2.1 General format of ggplot

The general format of ggplot is that we call some generic function, then we can just build on it by (literally) adding to it other components. Now we always start with the base ggplot function which has two main inputs the dataframe and then the aesthetic. ggplot is extremely flexible and I can't begin to scratch the surface of what you can do here so take a look at some other examples or the cheat sheet.

Suppose I want a histogram of penguins bill length in mm. I tell ggplot to look at my dataframe penguins and then I tell it to look for a specific column by its column name. Note that I don't have to subset my dataframe at all before this if I want to use entire columns, no matter how many other columns ggplot only looks at the ones I tell it to.

```{r}
ggplot(penguins, aes(x=bill_length_mm))
```

So R here has outputted nothing because I have told it only what the data frame and the column I want inputted is but I haven't specified which type of plot I want. So my next line I literally add onto it to tell R to make a histogram

```{r}
ggplot(penguins, aes(x=bill_length_mm)) +
  geom_histogram() # this is the line that tells it to make a histogram
```


So R has made a histogram here but notice that we don't have density on the y axis we just have counts which is not what we usually want, so we can add another argument to aes that specifically tells it to use the density on the y axis.


```{r}
ggplot(penguins, aes(x=bill_length_mm, y=..density..)) +
  geom_histogram() # this is the line that tells it to make a histogram
```


Now we have a histogram like we want it. I will add a title, change the theme and change the axis titles and we can be done for now it's really that simple.

```{r}
ggplot(penguins, aes(x=bill_length_mm, y=..density..)) +
  geom_histogram() + # this is the line that tells it to make a histogram 
  xlab("Bill length in mm")+ # changing the x axis label
  ggtitle("Penguin bill length Histogram")+ # adding the title
  theme_bw() # changing the theme for fun 



```




# 3 The Rep function and sampling

## 3.1 A simple sampling example

Now R is made for statistics and it has amazing random sampling functionality. If you need to sample from something oftentimes you can. Sampling is very important in any statistical practice since it allows us to generate fake data. When I say sampling I essentially mean simulating data. For instance I can simulate a coin toss many times. Let 1 denote heads and 0 denote tails.



```{r}
coin <- c(0,1)
```

From now on for reproducibility I will set a seed (what this does is allows for you to get the exact same random results as I get when you run these functions).

```{r}
set.seed(11)
```



My coin here is simply a vector with a 0 and a 1. I now need a function to randomly pick one of those with equal probability, This is the sample function

```{r}
sample(coin ,size=1)
```

So I have drawn heads here, but this is slow for me to run this manually so many times! This is what the size option is for. Let's say I wanted to flip 100 coins.

```{r, error=TRUE}
sample(coin, size=100)
```

We've received an error that says "cannot take a sample larger than the population when `replace = FALSE`. This is because what R does by default is that it treats your vector like a hat we're pulling papers out of. First it goes in and pulls out a random entry from the vector (in our case this was the 1), but by default it doesn't put this back into the hat, so then the next draw from the vector hat is whatever is left which in our case is just the 0. Finally on the third draw there are no numbers left in the hat to draw from so R spits out an error. We want R to put the papers back into the hat as if we are flipping the coin brand new. We can do this with the `replace=TRUE` argument.


```{r}
flips<-sample(coin, size=100, replace=TRUE)
flips
```


So we've now received our coin draws. Hopefully since we know this is a fair coin (why?), we can assume that we will have about 50 heads. I can just sum to check

```{r}
sum(flips)
```


That's pretty close to 50. In additon we can see the proportion of heads by dividing by the length.

```{r}
sum(flips)/length(flips)
```


An important thing to note is that this is exactly the same as taking the mean which we define as the sum of all our observations divided by the length

```{r}
mean(flips)
```


## 3.2 More complicated sampling with rep

Suppose I wanted to flip a coin with probability 1/56 of landing on heads. We can make this with a vector of 55 zeros and a single one. Note that in defining `weird_coin` I use rep, because I'm putting the same value so many times I don't want to write it out so I tell with `rep(0,55)` give me a vector with 55 zeros then with `c(rep(0,55),1)` I append a single one to the new vector.

```{r}
weird_coin <- c(rep(0,55),1)
```



So here I calculate the mean of this (again the same as the proportion as shown above), this should be fairly close to 1/56


```{r}
close<-mean(sample(weird_coin,1000,replace=TRUE))

close-(1/56)

```
It is pretty close. \ 

Someone asked about flipping tails rather than heads well in this case if I made the proability of heads 1, I can just do $1-P(\text{heads})$ (the complement rule) or I could replace the vector with the complementary vector. This is just we switch the ones and zeroes.

```{r}
weird_coin_tails <- 1-weird_coin # Why does this work?

close_tails<-mean(sample(weird_coin_tails,1000,replace=TRUE))

close_tails-(1-(1/56))

```

Again this is pretty close to what we'd expect it to be.

## 3.3 an extension of what we know (simulating things we don't know the answer to)






Sampling is a rather simple function but we can sometimes make it cater to some more complicated problems however almost all of them can essentially be boiled down to coin flips of some kind. For instance on a previous homework we were mostly doing simulations to confirm something we already knew. Here is an example of simulating with sampling to show something more complicated. All of this can be solved by hand but would be tedious. Don't worry if you don't understand the coding here (in fact its coded rather poorly by me) but this is is trying to see the probability of rolling three die and seeing the probability of getting a dice roll 10 or higher. Inside of the for loop is what is important, I'm sampling three draws with replacement from our dice then summing them together. I am then adding these sums to a vector. After this I take the mean of the number of times the sum was greater than 10. This should approximate the probabilty of rolling 3 dice and having a sum greater than 10. (this is mathematically supported by something called the law of large numbers).
 
```{r}
dice<- c(1:6)

z <- replicate(100000,sum(sample(dice,replace=TRUE,size=3)))


mean(z>=10)

```



# 4 Probability

## 4.1 A brief introduction

I will assume knowledge of basic probability rules learned in lecture such as multiplication rule and addition rule. Key among these is the definition of independence which I will emphasize here. Denote $$P(A \text{ and } B) \equiv P(A,B)$$. Recall that two events $A,B$ are independent if and only if

\begin{align*}
P(A,B)&=P(A)P(B)
\end{align*}

Suppose that $P(A) \neq 0$. We know by the multiplication rule that 

\begin{align*}
P(A,B)&=P(B|A)P(A)
\end{align*}

Combining these two facts we see that 



\begin{align*}
P(B|A)P(A)&=P(B)P(A))\\
P(B|A)&=P(B)
\end{align*}


which can be interpreted as the fact that knowing $A$ has no effect on the probability of $B$ happening! 


## 4.2 Binomial Distribution

The easiest way to think of the binomial distribution is that it is simply a sum of independent coin flips. Problems solved with this distribution are of the form "What is the probability of getting 6 heads in 10 coin flips". Let $X$ be the sum of the results of $n$ coin flips each with probability of heads being $p$. Then we say $X\thicksim \text{binomial}(n,p)$ which is read that $X$ has the probability distribution binomial with parameters $n$ and $p$. We can then compute the probability that  $X=k$ (the probability of $k$ heads in $n$ tosses with each toss being independently heads with probability $p$), written $P(X=k)$. We have that 

$$P(X=k)= \binom{n}{k}p^{k}(1-p)^{n-k}$$
Note that the $p^{k}(1-p)^{n-k}$ is simply the probability of having the heads show up in one specific spot within the $n$ tosses. The $\binom{n}{k}$ accounts for the other spots we can put the successful tosses. Therefore the binomial distribution is both an application of multiplication and the addition rule with both independence and mutually exclusive events (Don't worry if you don't understand this).


## 4.3 Computing binomial probabilities in R

The `dbinom` function in R evaluates the binomial formula above it takes in arguments `x`,`size` and `prob`. For our purposes `x` refers to $k$, `size` refers to $n$ and `prob` refers to $p$.

So if I wanted the probability of seeing 5 heads in 10 fair coin tosses I would evaluate

```{r}


dbinom(x=5,size=10,prob=1/2)

```

The `choose` function on the other hand simply evaluates $\binom{n}{k}=\frac{n!}{(n-k)!k!}$ (The function takes arguments `n` and `k` as in the formula). So if I wanted to evaluate the same probability I could do:

```{r}
# the same probability as above

choose(10,5) * (0.5)^(5) * (1-0.5)^(10-5)

```


This is clearly more tedious and the choose function should really only be used if you need to use choose specifically.

### An interlude on the binomial coefficient

$\binom{n}{k} \equiv \frac{n!}{(n-k)!k!}$ read "n choose k" is a special value in combinatorics which is the number of ways to choose an unordered subset of $k$ elements from a set of size $n$. For instance the number of teams of 3 people I can make from 9 people total is $\binom{9}{3}=84$ (check with R!). 

# 5 R Markdown 

R Markdown is one of my favorite tools. If you've been to my section or to my office hours you've seen me use it since I don't usually code within R scripts. In fact this document is written in R markdown. Working within chunks allows for easily organized code and reproducibility. In addition all the math here is embedded via LaTex, a very popular way to type complicated math. As usual I recommend never working in the console except for specific instances of execution of R code.